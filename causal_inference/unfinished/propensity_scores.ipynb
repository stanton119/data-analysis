{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity scoring\n",
    "\n",
    "TODO\n",
    "*   Comparing propensity scoring to other causal methods, do we observe equivalent results?\n",
    "*   Linear case - we can use an all features logistic regression\n",
    "*   Baseline\n",
    "    *   with no confounders\n",
    "    *   with all features\n",
    "*   Use propensity scores\n",
    "    *   as a feature\n",
    "    *   as inverse sample weights\n",
    "    *   manual estimator\n",
    "*   econml solution\n",
    "*   Compare all results\n",
    "*   Non linear - use a GBM to find P(T|X)\n",
    "    *   Show that using all features with a linear model doesnt work\n",
    "    *   Show that GBM based propensity scores with a linear model work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy data\n",
    "\n",
    "We create a data generating function to produce some dummy features with confounding and generate random outcomes from a linear model.\n",
    "\n",
    "$P(T|X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def print_results(array):\n",
    "    print([f\"{_x:.3f}\" for _x in array])\n",
    "\n",
    "\n",
    "def logit(p):\n",
    "    return np.log(p) - np.log(1 - p)\n",
    "\n",
    "\n",
    "def inv_logit(p):\n",
    "    return np.exp(p) / (1 + np.exp(p))\n",
    "\n",
    "\n",
    "def no_confound(x: np.array):\n",
    "    return np.zeros(x.shape[0])\n",
    "\n",
    "\n",
    "def linear_confound(x: np.array, a: float = 1.0, b: float = 0.5):\n",
    "    return a * x[:, 0] + b\n",
    "\n",
    "\n",
    "def generate_treatment_data(\n",
    "    n_samples: int = 1000,\n",
    "    n_features: int = 4,\n",
    "    treatment_binary: bool = False,\n",
    "    seed: int = None,\n",
    "    confounding_fcn: callable = None,\n",
    "    treatment_noise: float = 0.1,\n",
    "):\n",
    "    if confounding_fcn is None:\n",
    "        confounding_fcn = no_confound\n",
    "\n",
    "    rand = np.random.default_rng(seed)\n",
    "\n",
    "    # generate random features\n",
    "    x = rand.normal(\n",
    "        loc=rand.normal(size=n_features),\n",
    "        scale=rand.exponential(size=n_features),\n",
    "        size=(n_samples, n_features),\n",
    "    )\n",
    "\n",
    "    t_x = confounding_fcn(x)\n",
    "    if treatment_binary:\n",
    "        t = rand.binomial(n=1, p=inv_logit(t_x), size=n_samples)\n",
    "    else:\n",
    "        t = treatment_noise * rand.normal(size=n_samples) + t_x\n",
    "\n",
    "    x = np.concatenate([t[:, np.newaxis], x], axis=1)\n",
    "\n",
    "    t_col = \"t\"\n",
    "    x_cols = [f\"x_{idx+1}\" for idx in range(n_features)]\n",
    "\n",
    "    return pd.DataFrame(data=x, columns=[t_col] + x_cols), t_col, x_cols\n",
    "\n",
    "\n",
    "def generate_outcome_data(\n",
    "    x: pd.DataFrame,\n",
    "    outcome_binary: bool = False,\n",
    "    outcome_noise: float = 0.1,\n",
    "    seed: int = None,\n",
    "    bias: float = None,\n",
    "    weights: np.array = None,\n",
    "):\n",
    "    rand = np.random.default_rng(seed)\n",
    "\n",
    "    n_samples, n_features = x.shape\n",
    "    if bias is None:\n",
    "        bias = rand.normal()\n",
    "    if weights is None:\n",
    "        weights = rand.normal(size=(n_features, 1))\n",
    "    y = bias + np.dot(x, weights) + outcome_noise * rand.normal()\n",
    "\n",
    "    if outcome_binary:\n",
    "        y_avg = inv_logit(y)\n",
    "        y = rand.binomial(n=1, p=y_avg, size=(n_samples, 1))\n",
    "    else:\n",
    "        y_avg = None\n",
    "\n",
    "    return y, bias, weights, y_avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score\n",
    "\n",
    "The propensity score is the probability of each row being within the treatment group.\n",
    "The treatment in this case is binary.\n",
    "\n",
    "Ref:\n",
    "https://matheusfacure.github.io/python-causality-handbook/11-Propensity-Score.html\n",
    "\n",
    "We start with the linear case.\n",
    "\n",
    "We create data from a linear model where a linear regression model would be ideal.\n",
    "\n",
    "We:\n",
    "1. generate the data\n",
    "2. fit a linear regression model with all the features and treatment\n",
    "3. fit a linear regression model with only the treatment, ignoring the confounding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "True treatment uplift\n",
      "['-0.132']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# generate data\n",
    "x_df, t_col, x_cols = generate_treatment_data(\n",
    "    treatment_binary=True, confounding_fcn=linear_confound, seed=0\n",
    ")\n",
    "y, bias, weights, _ = generate_outcome_data(x=x_df, outcome_binary=False, seed=0)\n",
    "\n",
    "print(\"True weights\")\n",
    "print_results(weights.flatten())\n",
    "\n",
    "print(\"True treatment uplift\")\n",
    "print_results(weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring a confounder gives biased estimates of the treatment uplift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True treatment uplift\n",
      "['-0.132']\n",
      "Est treatment uplift, missing confounders, biased results:\n",
      "['0.056']\n",
      "0.056\n"
     ]
    }
   ],
   "source": [
    "print(\"True treatment uplift\")\n",
    "print_results(weights[0])\n",
    "\n",
    "linear_model = sm.OLS(y, sm.add_constant(x_df[t_col])).fit()\n",
    "print(\"Est treatment uplift, missing confounders, biased results:\")\n",
    "print_results(np.array(linear_model.params)[1:])\n",
    "print(f\"{linear_model.params[t_col]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model all features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True treatment uplift\n",
      "['-0.132']\n",
      "Est treatment uplift\n",
      "-0.132\n"
     ]
    }
   ],
   "source": [
    "print(\"True treatment uplift\")\n",
    "print_results(weights[0])\n",
    "\n",
    "linear_model = sm.OLS(y, sm.add_constant(x_df[[t_col] + x_cols])).fit()\n",
    "print(\"Est treatment uplift\")\n",
    "print(f\"{linear_model.params[t_col]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting propensity scores\n",
    "Predicting treatment allocation T given features X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.642029\n",
      "         Iterations 5\n",
      "Est weights, all features:\n",
      "['0.794', '-0.019', '-0.181', '0.039']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0.576584\n",
       "1      0.406237\n",
       "2      0.562914\n",
       "3      0.620872\n",
       "4      0.722216\n",
       "         ...   \n",
       "995    0.785712\n",
       "996    0.711037\n",
       "997    0.546930\n",
       "998    0.712151\n",
       "999    0.756375\n",
       "Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit models\n",
    "t_model = sm.Logit(x_df[t_col], sm.add_constant(x_df[x_cols])).fit()\n",
    "print(\"Est weights, all features:\")\n",
    "print_results(np.array(t_model.params)[1:])\n",
    "\n",
    "t_prop = t_model.predict(sm.add_constant(x_df[x_cols]))\n",
    "t_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the propensity score as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True treatment uplift\n",
      "['-0.132']\n",
      "Est weights, all features:\n",
      "['-0.130']\n"
     ]
    }
   ],
   "source": [
    "print(\"True treatment uplift\")\n",
    "print_results(weights[0])\n",
    "\n",
    "linear_model = sm.OLS(\n",
    "    y, sm.add_constant(np.stack([x_df[t_col], t_prop]).transpose())\n",
    ").fit()\n",
    "print(\"Est weights, all features:\")\n",
    "print_results(np.array(linear_model.params)[[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the propensity score as a sample weight\n",
    "Inverse propensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True treatment uplift\n",
      "['-0.132']\n",
      "Est weights, all features:\n",
      "['-0.130']\n"
     ]
    }
   ],
   "source": [
    "print(\"True treatment uplift\")\n",
    "print_results(weights[0])\n",
    "\n",
    "linear_model = sm.OLS(\n",
    "    y, sm.add_constant(np.stack([x_df[t_col], t_prop]).transpose())\n",
    ").fit()\n",
    "print(\"Est weights, all features:\")\n",
    "print_results(np.array(linear_model.params)[[1]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intercept_page_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
