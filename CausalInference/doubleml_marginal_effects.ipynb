{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoubleML with binary variables and marginal effects\n",
    "\n",
    "When using DoubleML, what do we do with binary outcomes or binary treatments? It seems like we just plough ahead and we the same models we would have if we used continuous outcomes.\n",
    "\n",
    "Here we explore the effects of using appropriate models and 'less' appropriate models to see if there's an actual difference.\n",
    "\n",
    "Ref:\n",
    "https://github.com/py-why/EconML/issues/204"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy data\n",
    "\n",
    "We create a data generating function to produce some dummy features with confounding and generate random outcomes from a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def print_results(array):\n",
    "    print([f\"{_x:.3f}\" for _x in array])\n",
    "\n",
    "\n",
    "def logit(p):\n",
    "    return np.log(p) - np.log(1 - p)\n",
    "\n",
    "\n",
    "def inv_logit(p):\n",
    "    return np.exp(p) / (1 + np.exp(p))\n",
    "\n",
    "\n",
    "def no_confound(x: np.array):\n",
    "    return np.zeros(x.shape[0])\n",
    "\n",
    "\n",
    "def linear_confound(x: np.array, a: float = 1.0, b: float = 0.5):\n",
    "    return a * x[:, 0] + b\n",
    "\n",
    "\n",
    "def generate_treatment_data(\n",
    "    n_samples: int = 1000,\n",
    "    n_features: int = 4,\n",
    "    treatment_binary: bool = False,\n",
    "    seed: int = None,\n",
    "    confounding_fcn: callable = None,\n",
    "    treatment_noise: float = 0.1,\n",
    "):\n",
    "    if confounding_fcn is None:\n",
    "        confounding_fcn = no_confound\n",
    "\n",
    "    rand = np.random.default_rng(seed)\n",
    "\n",
    "    # generate random features\n",
    "    x = rand.normal(\n",
    "        loc=rand.normal(size=n_features),\n",
    "        scale=rand.exponential(size=n_features),\n",
    "        size=(n_samples, n_features),\n",
    "    )\n",
    "\n",
    "    t_x = confounding_fcn(x)\n",
    "    if treatment_binary:\n",
    "        t = rand.binomial(n=1, p=inv_logit(t_x), size=n_samples)\n",
    "    else:\n",
    "        t = treatment_noise * rand.normal(size=n_samples) + t_x\n",
    "\n",
    "    x = np.concatenate([t[:, np.newaxis], x], axis=1)\n",
    "\n",
    "    t_col = \"t\"\n",
    "    x_cols = [f\"x_{idx+1}\" for idx in range(n_features)]\n",
    "\n",
    "    return pd.DataFrame(data=x, columns=[t_col] + x_cols), t_col, x_cols\n",
    "\n",
    "\n",
    "def generate_outcome_data(\n",
    "    x: pd.DataFrame,\n",
    "    outcome_binary: bool = False,\n",
    "    outcome_noise: float = 0.1,\n",
    "    seed: int = None,\n",
    "    bias: float = None,\n",
    "    weights: np.array = None,\n",
    "):\n",
    "    rand = np.random.default_rng(seed)\n",
    "\n",
    "    n_samples, n_features = x.shape\n",
    "    if bias is None:\n",
    "        bias = rand.normal()\n",
    "    if weights is None:\n",
    "        weights = rand.normal(size=(n_features, 1))\n",
    "    y = bias + np.dot(x, weights) + outcome_noise * rand.normal()\n",
    "\n",
    "    if outcome_binary:\n",
    "        y_avg = inv_logit(y)\n",
    "        y = rand.binomial(n=1, p=y_avg, size=(n_samples, 1))\n",
    "    else:\n",
    "        y_avg = None\n",
    "\n",
    "    return y, bias, weights, y_avg\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear case\n",
    "\n",
    "We start with the linear case.\n",
    "\n",
    "We create data from a linear model where a linear regression model would be ideal.\n",
    "\n",
    "We:\n",
    "1. generate the data\n",
    "2. fit a linear regression model with all the features and treatment\n",
    "3. fit a linear regression model with only the treatment, ignoring the confounding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "Est weights, all features:\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "Est weights, missing confounders, biased results:\n",
      "['0.479']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# generate data\n",
    "x_df, t_col, x_cols = generate_treatment_data(\n",
    "    treatment_binary=False, confounding_fcn=linear_confound, seed=0\n",
    ")\n",
    "y, bias, weights, _ = generate_outcome_data(x=x_df, outcome_binary=False, seed=0)\n",
    "\n",
    "print(\"True weights\")\n",
    "print_results(weights.flatten())\n",
    "\n",
    "\n",
    "# fit models\n",
    "linear_model = sm.OLS(y, sm.add_constant(x_df[[t_col] + x_cols])).fit()\n",
    "print(\"Est weights, all features:\")\n",
    "print_results(np.array(linear_model.params)[1:])\n",
    "\n",
    "linear_model = sm.OLS(y, sm.add_constant(x_df[t_col])).fit()\n",
    "print(\"Est weights, missing confounders, biased results:\")\n",
    "print_results(np.array(linear_model.params)[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression works as expected and when we don't include the confounder features we get a biased estimate for the treatment uplift."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate marginal effects\n",
    "The marginal effect represents the change in `y` given a unit change in the treatment `t` (or the features `x` as well).\n",
    "\n",
    "We calculate this by estimating derivatives in `y` for each feature to represent the average marginal effects.\n",
    "For the linear data model, these marginal effects are the same as the data generating weights.\n",
    "When we estimate them, the results are, as expected, asymptotically equal to the estimate linear regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True est. marginal effects:\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n"
     ]
    }
   ],
   "source": [
    "def get_marginal_effects(x, d_x: float = 1.0, model_fcn=None):\n",
    "    d_y = []\n",
    "    for col in x.columns:\n",
    "        _x = x.copy()\n",
    "        _x[col] = _x[col] + d_x\n",
    "        d_y.append((model_fcn(_x) - model_fcn(x)).mean() / d_x)\n",
    "\n",
    "    return d_y\n",
    "\n",
    "\n",
    "print(\"True est. marginal effects:\")\n",
    "print_results(get_marginal_effects(\n",
    "    x=x_df,\n",
    "    model_fcn=lambda x: generate_outcome_data(\n",
    "        x, outcome_binary=False, bias=bias, weights=weights, seed=0\n",
    "    )[0],\n",
    ")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double ML\n",
    "\n",
    "Assume all features are confounders.\n",
    "Assume no features for CATE.\n",
    "\n",
    "We can use GBMs for the models for `y` and `t` without creating bias.\n",
    "We get similar results if we use linear regression for these.\n",
    "\n",
    "As the data is generated from a linear model, linear regression is the ideal model to use, so we get slightly worse results with GBMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "Est marginal effect - linear models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Uncertainty of Mean Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>mean_point</th> <th>stderr_mean</th>        <th>zstat</th>        <th>pvalue</th> <th>ci_mean_lower</th> <th>ci_mean_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>-0.132</td>       <td>0.0</td>     <td>-1232558224036509.5</td>   <td>0.0</td>     <td>-0.132</td>        <td>-0.132</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Distribution of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>std_point</th> <th>pct_point_lower</th> <th>pct_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0.0</td>        <td>-0.132</td>          <td>-0.132</td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Total Variance of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>stderr_point</th> <th>ci_point_lower</th> <th>ci_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>0.0</td>         <td>-0.132</td>         <td>-0.132</td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<econml.inference._inference.PopulationSummaryResults at 0x1516bbdc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est marginal effect - GBMs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Uncertainty of Mean Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>mean_point</th> <th>stderr_mean</th>  <th>zstat</th> <th>pvalue</th> <th>ci_mean_lower</th> <th>ci_mean_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>-0.092</td>      <td>0.033</td>    <td>-2.816</td>  <td>0.005</td>    <td>-0.156</td>        <td>-0.028</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Distribution of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>std_point</th> <th>pct_point_lower</th> <th>pct_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0.0</td>        <td>-0.092</td>          <td>-0.092</td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Total Variance of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>stderr_point</th> <th>ci_point_lower</th> <th>ci_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>0.033</td>        <td>-0.156</td>         <td>-0.028</td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<econml.inference._inference.PopulationSummaryResults at 0x104ea9870>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import econml.dml\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "\n",
    "\n",
    "est = econml.dml.LinearDML(\n",
    "    model_t=sklearn.linear_model.LinearRegression(),\n",
    "    model_y=sklearn.linear_model.LinearRegression(),\n",
    "    random_state=0,\n",
    ")\n",
    "est.fit(Y=y, T=x_df[t_col], X=None, W=x_df.drop(columns=t_col))\n",
    "\n",
    "print(\"True weights\")\n",
    "print_results(weights.flatten())\n",
    "\n",
    "print(\"Est marginal effect - linear models\")\n",
    "display(est.const_marginal_ate_inference())\n",
    "\n",
    "\n",
    "est = econml.dml.LinearDML(\n",
    "    model_t=sklearn.ensemble.GradientBoostingRegressor(random_state=0),\n",
    "    model_y=sklearn.ensemble.GradientBoostingRegressor(random_state=0),\n",
    "    random_state=0,\n",
    ")\n",
    "est.fit(Y=y, T=x_df[t_col], X=None, W=x_df.drop(columns=t_col))\n",
    "\n",
    "print(\"Est marginal effect - GBMs\")\n",
    "display(est.const_marginal_ate_inference())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have agreement for the treatment effect over linear regression, doubleML and this matches the average marginal effect."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary outcome case\n",
    "\n",
    "In this case the linear model coefficients are not the same as the average marginal effect.\n",
    "\n",
    "Here, the marginal effect is the average change in probability of observing a positive outcome, also known as percentage basis points.\n",
    "\n",
    "Here we see that the linear regression coefficients do not match the data weights, as expected.\n",
    "The logistic regression model is the appropriate model to use and we recover the data weights without bias.\n",
    "\n",
    "Side note: As the binary outcome introduces a lot of noise we increase the number of samples to get reasonable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "Est weights, linear regression:\n",
      "['-0.024', '0.143', '0.024', '-0.124', '0.084']\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657852\n",
      "         Iterations 5\n",
      "Est weights, logistic regression:\n",
      "['-0.104', '0.613', '0.103', '-0.533', '0.360']\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "x_df, t_col, x_cols = generate_treatment_data(\n",
    "    treatment_binary=False, confounding_fcn=linear_confound, n_samples=int(1e6), seed=0\n",
    ")\n",
    "y, bias, weights, y_avg = generate_outcome_data(x=x_df, outcome_binary=True, seed=0)\n",
    "\n",
    "print(\"True weights\")\n",
    "print_results(weights.flatten())\n",
    "\n",
    "# fit models\n",
    "linear_model = sm.OLS(y, sm.add_constant(x_df[[t_col] + x_cols])).fit()\n",
    "print(\"Est weights, linear regression:\")\n",
    "print_results(np.array(linear_model.params)[1:])\n",
    "\n",
    "logit_model = sm.Logit(y, sm.add_constant(x_df[[t_col] + x_cols])).fit()\n",
    "print(\"Est weights, logistic regression:\")\n",
    "print_results(np.array(logit_model.params)[1:])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if we find the average marginal effect from the logistic model we get the linear regression coefficients.\n",
    "\n",
    "We use the average `y` to calculate the true marginal effects as it reduces the noise a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True est. marginal effects:\n",
      "['-0.030', '0.148', '0.024', '-0.119', '0.084']\n",
      "Average marginal effect, logistic regression:\n",
      "['-0.024', '0.143', '0.024', '-0.124', '0.084']\n",
      "Est weights, linear regression:\n",
      "['-0.024', '0.143', '0.024', '-0.124', '0.084']\n"
     ]
    }
   ],
   "source": [
    "print(\"True est. marginal effects:\")\n",
    "marginal_effects = get_marginal_effects(\n",
    "    x=x_df,\n",
    "    model_fcn=lambda x: generate_outcome_data(\n",
    "        x, outcome_binary=True, bias=bias, weights=weights, seed=0\n",
    "    )[-1],\n",
    ")\n",
    "print_results(marginal_effects)\n",
    "\n",
    "\n",
    "print(\"Average marginal effect, logistic regression:\")\n",
    "print_results(logit_model.get_margeff().margeff)\n",
    "\n",
    "print(\"Est weights, linear regression:\")\n",
    "print_results(np.array(linear_model.params)[1:])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore if we are interested in the average marginal effects we don't need to use logistic regression.\n",
    "\n",
    "This opens the door to use doubleML with regressors to estimate the average marginal effect even if we have binary outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True est. marginal effects:\n",
      "['-0.030', '0.148', '0.024', '-0.119', '0.084']\n",
      "Est marginal effect\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Uncertainty of Mean Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>mean_point</th> <th>stderr_mean</th>  <th>zstat</th> <th>pvalue</th> <th>ci_mean_lower</th> <th>ci_mean_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>-0.024</td>      <td>0.005</td>    <td>-5.018</td>   <td>0.0</td>     <td>-0.033</td>        <td>-0.015</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Distribution of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>std_point</th> <th>pct_point_lower</th> <th>pct_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0.0</td>        <td>-0.024</td>          <td>-0.024</td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Total Variance of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>stderr_point</th> <th>ci_point_lower</th> <th>ci_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>0.005</td>        <td>-0.033</td>         <td>-0.015</td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<econml.inference._inference.PopulationSummaryResults at 0x1468289d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 1:\n",
    "    est = econml.dml.LinearDML(\n",
    "        model_t=sklearn.ensemble.HistGradientBoostingRegressor(random_state=0),\n",
    "        model_y=sklearn.ensemble.HistGradientBoostingRegressor(random_state=0),\n",
    "        random_state=0,\n",
    "    )\n",
    "else:\n",
    "    est = econml.dml.LinearDML(\n",
    "        model_t=sklearn.linear_model.LinearRegression(),\n",
    "        model_y=sklearn.linear_model.LinearRegression(),\n",
    "        random_state=0,\n",
    "    )\n",
    "est.fit(Y=y, T=x_df[t_col], X=None, W=x_df.drop(columns=t_col))\n",
    "\n",
    "print(\"True est. marginal effects:\")\n",
    "print_results(marginal_effects)\n",
    "\n",
    "print(\"Est marginal effect\")\n",
    "display(est.const_marginal_ate_inference())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary treatment case\n",
    "\n",
    "If we have a binary treatment the final model should be a linear regression.\n",
    "\n",
    "Here the marginal effects are equal to the data weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "Est weights, linear regression:\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "True est. marginal effects:\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "x_df, t_col, x_cols = generate_treatment_data(\n",
    "    treatment_binary=True, confounding_fcn=linear_confound, n_samples=int(1e6), seed=0\n",
    ")\n",
    "y, bias, weights, y_avg = generate_outcome_data(x=x_df, outcome_binary=False, seed=0)\n",
    "\n",
    "print(\"True weights\")\n",
    "print_results(weights.flatten())\n",
    "\n",
    "\n",
    "# fit models\n",
    "linear_model = sm.OLS(y, sm.add_constant(x_df[[t_col] + x_cols])).fit()\n",
    "print(\"Est weights, linear regression:\")\n",
    "print_results(np.array(linear_model.params)[1:])\n",
    "\n",
    "print(\"True est. marginal effects:\")\n",
    "marginal_effects = get_marginal_effects(\n",
    "    x=x_df,\n",
    "    model_fcn=lambda x: generate_outcome_data(\n",
    "        x, outcome_binary=False, bias=bias, weights=weights, seed=0\n",
    "    )[0],\n",
    ")\n",
    "print_results(marginal_effects)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see that using regression based double ML returns the same marginal effect back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True est. marginal effects:\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "Est marginal effect\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Uncertainty of Mean Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>mean_point</th> <th>stderr_mean</th>   <th>zstat</th>   <th>pvalue</th> <th>ci_mean_lower</th> <th>ci_mean_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>-0.132</td>       <td>0.0</td>     <td>-1795.605</td>   <td>0.0</td>     <td>-0.132</td>        <td>-0.132</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Distribution of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>std_point</th> <th>pct_point_lower</th> <th>pct_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0.0</td>        <td>-0.132</td>          <td>-0.132</td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Total Variance of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>stderr_point</th> <th>ci_point_lower</th> <th>ci_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>0.0</td>         <td>-0.132</td>         <td>-0.132</td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<econml.inference._inference.PopulationSummaryResults at 0x1466fbf70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 1:\n",
    "    est = econml.dml.LinearDML(\n",
    "        model_t=sklearn.ensemble.HistGradientBoostingRegressor(random_state=0),\n",
    "        model_y=sklearn.ensemble.HistGradientBoostingRegressor(random_state=0),\n",
    "        random_state=0,\n",
    "    )\n",
    "else:\n",
    "    est = econml.dml.LinearDML(\n",
    "        model_t=sklearn.linear_model.LinearRegression(),\n",
    "        model_y=sklearn.linear_model.LinearRegression(),\n",
    "        random_state=0,\n",
    "    )\n",
    "est.fit(Y=y, T=x_df[t_col], X=None, W=x_df.drop(columns=t_col))\n",
    "\n",
    "print(\"True est. marginal effects:\")\n",
    "print_results(marginal_effects)\n",
    "\n",
    "print(\"Est marginal effect\")\n",
    "display(est.const_marginal_ate_inference())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary outcome and treatment case\n",
    "\n",
    "We see that the marginal effect from a logistic model, linear regression coefficient and the data marginal effect match well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights\n",
      "['-0.132', '0.640', '0.105', '-0.536', '0.362']\n",
      "True est. marginal effects:\n",
      "['-0.030', '0.147', '0.024', '-0.118', '0.083']\n",
      "Est weights, linear regression:\n",
      "['-0.030', '0.148', '0.024', '-0.123', '0.083']\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654005\n",
      "         Iterations 5\n",
      "Est weights, logistic regression:\n",
      "['-0.130', '0.641', '0.104', '-0.533', '0.358']\n",
      "Average marginal effect, logistic regression:\n",
      "['-0.030', '0.148', '0.024', '-0.123', '0.083']\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "x_df, t_col, x_cols = generate_treatment_data(\n",
    "    treatment_binary=True, confounding_fcn=linear_confound, n_samples=int(1e6), seed=0\n",
    ")\n",
    "y, bias, weights, y_avg = generate_outcome_data(x=x_df, outcome_binary=True, seed=0)\n",
    "\n",
    "print(\"True weights\")\n",
    "print_results(weights.flatten())\n",
    "\n",
    "print(\"True est. marginal effects:\")\n",
    "marginal_effects = get_marginal_effects(\n",
    "    x=x_df,\n",
    "    model_fcn=lambda x: generate_outcome_data(\n",
    "        x, outcome_binary=True, bias=bias, weights=weights, seed=0\n",
    "    )[-1],\n",
    ")\n",
    "print_results(marginal_effects)\n",
    "\n",
    "\n",
    "# fit models\n",
    "linear_model = sm.OLS(y, sm.add_constant(x_df[[t_col] + x_cols])).fit()\n",
    "print(\"Est weights, linear regression:\")\n",
    "print_results(np.array(linear_model.params)[1:])\n",
    "\n",
    "logit_model = sm.Logit(y, sm.add_constant(x_df[[t_col] + x_cols])).fit()\n",
    "print(\"Est weights, logistic regression:\")\n",
    "print_results(np.array(logit_model.params)[1:])\n",
    "\n",
    "print(\"Average marginal effect, logistic regression:\")\n",
    "print_results(logit_model.get_margeff().margeff)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see that using regression based double ML returns the same marginal effect back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True est. marginal effects:\n",
      "['-0.030', '0.147', '0.024', '-0.118', '0.083']\n",
      "Est marginal effect\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Uncertainty of Mean Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>mean_point</th> <th>stderr_mean</th>  <th>zstat</th>  <th>pvalue</th> <th>ci_mean_lower</th> <th>ci_mean_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>-0.03</td>      <td>0.001</td>    <td>-28.912</td>   <td>0.0</td>     <td>-0.032</td>        <td>-0.028</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Distribution of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>std_point</th> <th>pct_point_lower</th> <th>pct_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>0.0</td>         <td>-0.03</td>           <td>-0.03</td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Total Variance of Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>stderr_point</th> <th>ci_point_lower</th> <th>ci_point_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>0.001</td>        <td>-0.032</td>         <td>-0.028</td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<econml.inference._inference.PopulationSummaryResults at 0x157426da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est = econml.dml.LinearDML(\n",
    "    model_t=sklearn.ensemble.HistGradientBoostingRegressor(random_state=0),\n",
    "    model_y=sklearn.ensemble.HistGradientBoostingRegressor(random_state=0),\n",
    "    random_state=0,\n",
    ")\n",
    "est.fit(Y=y, T=x_df[t_col], X=None, W=x_df.drop(columns=t_col))\n",
    "\n",
    "print(\"True est. marginal effects:\")\n",
    "print_results(marginal_effects)\n",
    "\n",
    "print(\"Est marginal effect\")\n",
    "display(est.const_marginal_ate_inference())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intercept_page_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
