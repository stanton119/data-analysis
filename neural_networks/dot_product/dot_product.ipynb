{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing the dot/inner product through an MLP\n",
    "\n",
    "Dot products are commonly used in recommender systems to combine user and item embeddings.\n",
    "\n",
    "The dot product of two vectors (A and B) is the sum of the products of their corresponding elements:\n",
    "$$\n",
    "\\mathbf{a} \\cdot \\mathbf{b} = \\langle \\mathbf{a}, \\mathbf{b} \\rangle = \\sum_{i=1}^{n} a_i b_i\n",
    "$$\n",
    "\n",
    "\n",
    "Dense layers in a neural network work on the weighted sum of inputs. They dont directly capture interactions between features. We can concat two vector and push through a dense layer. The output of a dense layer is given as:\n",
    "$$\n",
    "g([\\mathbf{a} , \\mathbf{b}]) = \\sigma(\\mathbf{W} \\cdot ([\\mathbf{a} , \\mathbf{b}]) + \\mathbf{c})\n",
    "$$\n",
    "\n",
    "Where $[,]$ is the concatenation operation and $\\mathbf{W}$ and $\\mathbf{c}$ are the weight matrix and bias of the dense layer, respectively.\n",
    "\n",
    "In this notebook, we will explore how to represent the dot product using a neural network\n",
    "\n",
    "## TODO\n",
    "1. Create a model training framework\n",
    "2. Deep vs shallow\n",
    "3. data loader to create random dot product samples\n",
    "4. overfit small sample, with high epoch count\n",
    "   1. is learning rate correct?\n",
    "\n",
    "## Setup\n",
    "```\n",
    "uv add pytorch-lightning\n",
    "uv run mlflow ui --backend-store-uri experiments\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pytorch_lightning as pyl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Model(pyl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimension: int,\n",
    "        layer_sizes: List[int] = [32, 16],\n",
    "        learning_rate: float = 5e-3,\n",
    "        incl_multiplication: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.incl_multiplication = incl_multiplication\n",
    "        input_layer_size = dimension * 3 if incl_multiplication else dimension * 2\n",
    "        if layer_sizes is None:\n",
    "            self.output = nn.Linear(input_layer_size, 1)\n",
    "            # self.output.weight.data.fill_(1.0)\n",
    "            # self.output.bias.data.fill_(0.0)\n",
    "        else:\n",
    "            layer_sizes = [input_layer_size] + layer_sizes + [1]\n",
    "            layers = []\n",
    "            for i in range(len(layer_sizes) - 1):\n",
    "                layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "                layers.append(nn.ReLU())\n",
    "            self.output = nn.Sequential(*layers, nn.Linear(layer_sizes[-1], 1))\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        if self.incl_multiplication:\n",
    "            return self.output(torch.cat([a, b, a * b], dim=1)).flatten()\n",
    "        else:\n",
    "            return self.output(torch.cat([a, b], dim=1)).flatten()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        a, b, y = batch\n",
    "        y_hat = self(a, b)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        a, b, y = batch\n",
    "        y_hat = self(a, b)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        a, b, y = batch\n",
    "        y_hat = self(a, b)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "We will make a dataset that creates a random pair of vectors and their dot product.\n",
    "As the data is randomly generate each batch we don't need to be concerned with overfitting.\n",
    "Therefore we have only a train dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[0.3367],\n",
      "        [0.1288],\n",
      "        [0.2345],\n",
      "        [0.2303]])\n",
      "b: tensor([[ 0.5349],\n",
      "        [ 0.8094],\n",
      "        [ 1.1103],\n",
      "        [-1.6898]])\n",
      "Dot Product: tensor([ 0.1801,  0.1043,  0.2603, -0.3892])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "class RandomVectorDataset(Dataset):\n",
    "    def __init__(self, dimension: int, num_samples: int, seed: int = 42):\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.dimension = dimension\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        self.a = torch.randn(num_samples, dimension)\n",
    "        self.b = torch.randn(num_samples, dimension)\n",
    "        self.y = torch.sum(self.a * self.b, dim=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.a[idx, :], self.b[idx, :], self.y[idx]\n",
    "\n",
    "\n",
    "class RandomVectorDataset2(Dataset):\n",
    "    def __init__(self, dimension: int, num_samples: int, seed: int = 42):\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.dimension = dimension\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a = torch.randn(self.dimension)\n",
    "        b = torch.randn(self.dimension)\n",
    "        y = torch.dot(a, b)\n",
    "        return a, b, y\n",
    "\n",
    "\n",
    "dataset = RandomVectorDataset(dimension=1, num_samples=10)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "for batch in dataloader:\n",
    "    a, b, y = batch\n",
    "    print(f\"a: {a}\")\n",
    "    print(f\"b: {b}\")\n",
    "    print(f\"Dot Product: {y}\")\n",
    "    break  # Remove this break to iterate through the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "def setup_experiment():\n",
    "    mlf_logger = MLFlowLogger(experiment_name=\"dot_product\", tracking_uri=\"experiments\")\n",
    "    return mlf_logger\n",
    "\n",
    "\n",
    "def train(model, dataloader):\n",
    "    early_stopping = EarlyStopping(monitor=\"train_loss\", patience=2, mode=\"min\")\n",
    "    mlf_logger = setup_experiment()\n",
    "    trainer = pyl.Trainer(\n",
    "        max_epochs=300,\n",
    "        logger=mlf_logger,\n",
    "        log_every_n_steps=1,\n",
    "        callbacks=early_stopping,\n",
    "    )\n",
    "    trainer.fit(model, dataloader)\n",
    "\n",
    "    return trainer.test(model, dataloader)\n",
    "\n",
    "\n",
    "def train_loop(dimension: int, model_kwargs: dict = None):\n",
    "    _model_kwargs = {\"layer_sizes\": [dimension * 2, dimension], \"learning_rate\": 1e-2}\n",
    "    _model_kwargs.update(model_kwargs or {})\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    num_samples = 1_000_000\n",
    "    num_samples = 1024\n",
    "    batch_size = 1024\n",
    "    dataset = RandomVectorDataset(dimension=dimension, num_samples=num_samples)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = Model(dimension=dimension, **_model_kwargs)\n",
    "    loss = train(model=model, dataloader=dataloader)\n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | output | Sequential | 66     | train\n",
      "----------------------------------------------\n",
      "66        Trainable params\n",
      "0         Non-trainable params\n",
      "66        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "64        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=515e, train_loss_step=0.960, train_loss_epoch=0.960]\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.32it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_loss_epoch         0.96002197265625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# model, loss = train_loop(dimension=4, layers=[4, 2])\n",
    "# model, loss = train_loop(dimension=4, layers=[4])\n",
    "# model, loss = train_loop(dimension=4, layers=[16, 8, 4, 2])\n",
    "# model, loss = train_loop(dimension=2, layers=[4, 2])\n",
    "# model, loss = train_loop(dimension=1, layers=[2])\n",
    "# model, loss = train_loop(dimension=2, layers=[16, 8, 4, 2])\n",
    "# model, loss = train_loop(dimension=2, layers=[32, 32, 16, 16, 8, 8, 4, 4, 2, 2])\n",
    "# model, loss = train_loop(dimension=2, layers=[4]*30)\n",
    "# model, loss = train_loop(dimension=1, layers=[4]*100)\n",
    "# model, loss = train_loop(dimension=1, layers=[1024, 512, 128, 64, 32])\n",
    "# model, loss = train_loop(dimension=1)\n",
    "# model, loss = train_loop(dimension=1, model_kwargs={\"incl_multiplication\": True})\n",
    "# model, loss = train_loop(dimension=1, model_kwargs={\"layer_sizes\":[8, 8, 4, 4], \"incl_multiplication\": True})\n",
    "# model, loss = train_loop(\n",
    "#     dimension=1,\n",
    "#     model_kwargs={\"layer_sizes\": [16, 8, 8, 4, 4], \"incl_multiplication\": True, 'learning_rate': 1e-2},\n",
    "# )\n",
    "# model, loss = train_loop(\n",
    "#     dimension=1, model_kwargs={\"layer_sizes\": None, \"incl_multiplication\": True}\n",
    "# )\n",
    "model, loss = train_loop(\n",
    "    dimension=1, model_kwargs={\"layer_sizes\": [1] * 30, \"incl_multiplication\": True}\n",
    ")\n",
    "# model, loss = train_loop(dimension=1, layers=[10000, 512, 128, 64, 32])\n",
    "# model, loss = train_loop(dimension=1, layers=[64, 32, 16, 8, 4, 2])\n",
    "# model, loss = train_loop(dimension=1, layers=None)\n",
    "# model, loss = train_loop(dimension=2, layers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.6321,  0.6314,  0.3821],\n",
       "         [ 0.8511,  0.9255, -0.3002],\n",
       "         [-0.2286, -0.2052,  0.8763],\n",
       "         [-0.4934, -0.4419, -0.6459]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2503,  0.0763,  1.2434, -0.0285], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.8136, -0.3749,  1.2269, -0.4511]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.7480], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.7036]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.6541], requires_grad=True)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/4qby95090jbbq38_mh94x72r0000gn/T/ipykernel_30302/2643683158.py:31: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAIjCAYAAADxz9EgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANe5JREFUeJzt3QucXtO9P/6VewSJS+QiDXG/SxCXuPxUG6KUctrTFEdSpapU1T1RglJR15wScijac1qkFFU0StDWrXFtaRNKaFKVW5GQICTP//Vd/c90JplEhjUzmZn3+/XanWfvZ+/9rOeZLX0+s9b67jaVSqWSAAAAKKJtmdMAAAAQhCwAAICChCwAAICChCwAAICChCwAAICChCwAAICChCwAAICChCwAAICChCwAAICChCyAldxXv/rV1K9fv4917DnnnJPatGlTvE0s28UXX5w23HDD1K5duzRgwIC0snjooYfytRA/S1xbACybkAXwMcUX1hVZan6pbU3iC/xqq62WWpPf/OY36bTTTku77bZbuuGGG9IFF1zQaK/95S9/OV9vp59+evFzf/rTn651Ta+yyipp2223TWPGjEmLFy8u/noAzV37pm4AQHP1f//3f7XW//d//zfdd999S23fYostPtHrXHvttR/7i+yZZ56ZRowY8YlenxX3wAMPpLZt26brrrsudezYsdFed968eelXv/pV7pW66aab0oUXXli8B/NTn/pUGj16dH48Z86cdOONN6YTTzwxzZ49O33/+98v+loAzZ2QBfAx/dd//Vet9ccffzyHrCW3L2nBggWpS5cuK/w6HTp0+NhtbN++fV5oHLNmzcq9PKUCVqVSSe+9914+5/L84he/SIsWLUrXX399+sxnPpN+97vfpT333DOV1K1bt1rX9jHHHJM233zzdMUVV6Tvfe97eXgkAP9iuCBAA4phVltvvXV66qmn0v/7f/8vh6szzjgjP/fLX/4y7b///mnddddNnTp1ShtttFE677zz8pflmpacN/Pqq6/mXopLLrkkXXPNNfm4OH7HHXdMTzzxxEfOyYr1b33rW+mOO+7IbYtjt9pqqzRhwoSl2h9DHQcOHJg6d+6cX+d//ud/is/zuuWWW9IOO+yQg0T37t3zF/nXXnut1j4zZsxIRxxxRO5Nifb27t07feELX8ifRZUnn3wyDRkyJJ8jzrXBBhukr33ta7XOEz2CMcQt3m+8p549e6ZvfOMb6c0336y134qca0nxmcQQwfnz51cPq/vxj3+cn/vwww/z77bqdxW/z7gO3n///VrniO2f//zn07333ps/93jt+Mw/ys9+9rO09957p7322iv3nMZ6Q4vPL665t99+O4fLmtdm1fuuKbbHtVOl6jp66aWX8jW+xhpr5CAXv+f4Q0RN8ceL3XffPe8TQ1A322yz6v+OAFZG/rwJ0MD++c9/ps997nPpK1/5Sg4Q8cU+xBfR+MJ40kkn5Z8x1GzUqFF56FcUT/goMVwrvuBGSIgvqxdddFH6j//4jzR16tSP7P16+OGH02233ZaOPfbYtPrqq6cf/vCH6Ytf/GKaNm1aWnvttfM+zzzzTNp3331zoDn33HNz+Isei3XWWafQJ/OvzyC+VMeX9RiKNnPmzPTf//3f6ZFHHsmvH1+qQ7Ttz3/+czr++ONzEIkv9fHFO9pbtb7PPvvktsXwyDguvvDHe6wpPquq1/z2t7+dXnnllXTllVfm14rXjM9tRc+1pBgmGqF30qRJ6Uc/+lHetuuuu+afRx11VPrJT36SvvSlL6WTTz45/eEPf8jvd/Lkyen222+vdZ4XXnghHXLIIbmtX//613OgWJ5//OMf6cEHH8znD3Hs5Zdfnt9XQw9ZrApVVb+njzuXLEJsfB5PP/10/ux69OiRfvCDH+Tn4/cewTPmgMX1FyE1gln8vgBWWhUAijjuuOMqS/6zuueee+Zt48aNW2r/BQsWLLXtG9/4RqVLly6V9957r3rb8OHDK+uvv371+iuvvJLPufbaa1feeOON6u2//OUv8/Zf/epX1dvOPvvspdoU6x07dqy89NJL1dv++Mc/5u1XXHFF9bYDDjggt+W1116r3vbXv/610r59+6XOWZdo96qrrrrM5xcuXFjp0aNHZeutt668++671dvvuuuufP5Ro0bl9TfffDOvX3zxxcs81+233573eeKJJ5a5z+9///u8z89+9rNa2ydMmFBr+4qcqz7v+dlnn83nO+qoo2ptP+WUU/L2Bx54oHpb/J5jW7RpRV1yySWVVVZZpTJv3ry8/uKLL+ZzxPuo6cEHH8zb4+eyrq1liet48803r8yePTsvU6ZMqZx66qn5fPvvv/9S1+YNN9yw1Dlie1yPS16bX/va12rtd/DBB+dru8rll1+e94vXBWguDBcEaGDxl/foOVlSzXk20SMVxQT22GOPPFRqypQpH3neoUOHpjXXXLN6PY4N0ZP1UQYPHpyHrlWJXoKuXbtWHxu9Vvfff3866KCD8nDGKhtvvHHulSshhuRFr1H0psXQsyoxhDLm+tx99915vWqOUwxdXHJYX5WqnpS77rorffDBB8sclhjD0WJYXXzWVUsMVYyexOgNWtFz1cc999yTf0aPZU3RoxWq3meV6NWJoYorKoYGxmcWPZJhk002ye+p9JDBuCajdy+W+P1Eb+uBBx5Y59DA+oi5XTXFdRy9v9GjW/P3EcNrVTIEmgshC6CB9enTp85hWzEM6uCDD85f/CPgxJfXqsICc+fO/cjzrrfeerXWqwLXsoLI8o6tOr7q2Ag/7777bg5VS6pr28fxt7/9Lf+sazhcfImvej5Cagwd+/Wvf52HWsbcthgaGfO0qkSRhxhSGMMaYx5VzNeK+VE15zz99a9/zZ9rDEWrCgtVyzvvvFM9r2hFzlXf9xkVB5f83Hr16pUDRNX7rBmyVlQMN4yhjlEyPobQVS0xFzBCYlVQKSGGZcYQzZgvdtVVV+XrOioL1gzIH8dHXcfxx4R4fzHkMn7/Mez25z//ucAFrNTMyQJoYHVVhnvrrbfyl/kIVzHPJHqV4stqzEmJ+xytyBfIZVVz+9fIrIY7til85zvfSQcccEAu1hFf8s8666w8hyfmsW233XZ5XtCtt96aKzxGKfPYJwpVXHrppXlb9FTFZxoBa1k9PFVzzVbkXB/HihYL+ahKgjX99Kc/zT+jlHosdVUdrKsX9eNYddVVcw9olQg+22+/fS5AEXP6lvcelyzmUp9rMT6PqJYYPY3R6xcFWsaPH5+rKMZ9yVQ1BFZGerIAmkAMfYshUTHU6oQTTsgT++MLbM3hf00pwkiEvugVWVJd2z6O9ddfv7rQw5JiW9XzVSKIxhC7+GL9/PPPp4ULF+bgU9Muu+yS79kUQxEjTEVv4c0331x9fHzmEQ7is15y6d+//wqfq77vMwJe9KTVFEU+Imwv+T5XVISQKH4SFQVjKOSSSwwBbcgqg3H+6HmN6odRgCRUXb/xvmpasreuvqIn8LOf/Wy67LLL0l/+8pf8e4mAXTXEE2BlI2QBNIGqv77X7DmK0BDDsFaW9kXwiJ6jqF5XM2DFsL0SokR5hLlx48bVGooX549hcDHPKMQctbhXVE0RmGIOUtVxMbRsyV64AQMG5J9V+0QVu+hRiVLqS4oS61XBYEXOVR/77bdf/hml42uKwBCq3md9RXW9qO4XPVVRtXDJJYbZRQip+fsr7bTTTsvz1qreS/TMxhDL6Hmq6ZNc12+88cZS2z7J7wOgMRguCNAEorR3/NV/+PDhuZR4DLOKEuAr03C9uI9R9BpFz883v/nNHFCiLHjcW+vZZ59doXPEF/Dzzz9/qe1rrbVWLngRc60iJMTQySg9XlXCPeb/VA1/e/HFF3MvRoSkLbfcMt9cOcqex74xPydE+fL4Ih9z3CKARSGRa6+9Nn/prwo58RpRFj2GGUb7o0x7lGyPHqbo+YnXjXCyIueqj+ghi99zlHevGiYaZd7jdaKwSPREfRzRSxVheFkhLYpSfPe73829b0sW3Sglfh/xmUTZ9RjCGeX/Y+7UhRdemH9GkI7AFb/DjyuG08Y54n1Gr1/MnYvfT9wzLe6dBbAyErIAmkB8GY3CBDH87cwzz8yBK4ZeRZioT2W5hhQV6qJX6ZRTTslfoPv27Zu/8EYv04pUP6zqnYtjlxThJUJW3IQ2btAcX8pjLlrM+4lwE+GrqqpcvG4EsIkTJ+YgGiErCmNE8YMoUBGqgksEighfUUxkp512ykGkZiGJ6DWL9xVD3GIuUZwrAl189hEm63Ou+ogQsuGGG+bhoREQo+jFyJEj09lnn/2xzhfhNYJhhPUIrHWJMBztjXlbDRWywqmnnprnSl1xxRU5mMe93qIgRsxri99RVKOM6yh6LT+OCIvRY3f99dfnapDRUxa/oyhMEr8bgJVRm6jj3tSNAKD5iN6XmJ+05BwjAOBfzMkCYJmijHtNEazivk9RIhwAqJueLACWqXfv3nlIXwx1iwpxV199dS42EPdmipveAgBLMycLgGXad99900033ZRv/Bs3BR40aFC64IILBCwAWFmHC0a1oLi55Lrrrpsra0Wp4BW5t0zc/DD+z37jjTfOk4gBaBg33HBDLjoQJdTnzp2bbwQb/wYDACtpyJo/f34ubTt27NgV2v+VV17JJVyj3G2U3/3Od76TS8Tee++9Dd5WAACAZjUnK3qyoqxtVK1alijvG2Vin3/++eptcY+UuO9I/HUVAACgqTWrOVmPPfZYGjx4cK1tcT+Z6NFalpigXfOO8IsXL853j4971ESwAwAAWqdKpZJvOh/Tl9q2bds6Q1ZMvO7Zs2etbbE+b968XGZ4lVVWWeqY0aNH5xsWAgAA1GX69OnpU5/6VGqVIevjGDlyZK073cfE7fXWWy9/kF27dm3StgEAAE0nOmv69u2bVl999aLnbVYhq1evXmnmzJm1tsV6hKW6erFCVCGMZUlxjJAFAAC0KTyNqEmrC9ZX3J9l4sSJtbbdd999eTsAAMDKoElD1jvvvJNLscdSVaI9Hk+bNq16qN+wYcOq9z/mmGPS1KlT02mnnZamTJmSrrrqqvTzn/88nXjiiU32HgAAAFaakPXkk0+m7bbbLi8h5k7F41GjRuX1119/vTpwhQ022CCXcI/eq7i/1qWXXpp+9KMf5QqDAAAAK4OV5j5ZjTm5rVu3brkAhjlZAADQfFUqlfThhx+mRYsWLXOfDh06pHbt2jVqNmhWhS8AAADCwoUL88i3BQsWpI8qahHl2VdbbbXUWIQsAACgWVm8eHGu5xA9VHEj4Y4dO9ZZITB6umbPnp3+/ve/p0022WSZPVqlCVkAAECz68VavHhxvsdVly5dlrvvOuusk1599dX0wQcfNFrIalYl3AEAAKq0bdu20e+BtSKELAAAgIKELAAAgIKELAAAgIKELAAAgIKELAAAoFmqVCpF9ilNyAIAAJqVDh065J8fdSPiqnLvobHKtwf3yQIAAJqVdu3apTXWWCPNmjUrr8e9suoq1R730oqbEcfz7ds3XvQRsgAAgGanV69e+WdV0FrevbTWW2+9Rr1flpAFAAA0O23atEm9e/dOPXr0SB988MEy9+vYseMK3bS4JCELAABo1kMH2zXifKsVofAFAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABAQUIWAABASwpZY8eOTf369UudO3dOO++8c5o0adJy9x8zZkzabLPN0iqrrJL69u2bTjzxxPTee+81WnsBAABW2pA1fvz4dNJJJ6Wzzz47Pf3006l///5pyJAhadasWXXuf+ONN6YRI0bk/SdPnpyuu+66fI4zzjij0dsOAACw0oWsyy67LH39619PRxxxRNpyyy3TuHHjUpcuXdL1119f5/6PPvpo2m233dKhhx6ae7/22WefdMghh3xk7xcAAECLD1kLFy5MTz31VBo8ePC/G9O2bV5/7LHH6jxm1113zcdUhaqpU6eme+65J+23337LfJ33338/zZs3r9YCAADQUNqnJjJnzpy0aNGi1LNnz1rbY33KlCl1HhM9WHHc7rvvniqVSvrwww/TMcccs9zhgqNHj07nnntu8fYDAACslIUv6uOhhx5KF1xwQbrqqqvyHK7bbrst3X333em8885b5jEjR45Mc+fOrV6mT5/eqG0GAABalybryerevXtq165dmjlzZq3tsd6rV686jznrrLPS4Ycfno466qi8vs0226T58+eno48+On33u9/Nww2X1KlTp7wAAAC06J6sjh07ph122CFNnDixetvixYvz+qBBg+o8ZsGCBUsFqQhqIYYPAgAAtNqerBDl24cPH54GDhyYdtppp3wPrOiZimqDYdiwYalPnz55XlU44IADckXC7bbbLt9T66WXXsq9W7G9KmwBAAC02pA1dOjQNHv27DRq1Kg0Y8aMNGDAgDRhwoTqYhjTpk2r1XN15plnpjZt2uSfr732WlpnnXVywPr+97/fhO8CAADg39pUWtk4uyjh3q1bt1wEo2vXrk3dHAAAoIVlg2ZVXRAAAGBlJ2QBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAC0pJA1duzY1K9fv9S5c+e08847p0mTJi13/7feeisdd9xxqXfv3qlTp05p0003Tffcc0+jtRcAAGB52qcmNH78+HTSSSelcePG5YA1ZsyYNGTIkPTCCy+kHj16LLX/woUL0957752fu/XWW1OfPn3S3/72t7TGGms0SfsBAACW1KZSqVRSE4lgteOOO6Yrr7wyry9evDj17ds3HX/88WnEiBFL7R9h7OKLL05TpkxJHTp0+FivOW/evNStW7c0d+7c1LVr10/8HgAAgOZpXgNlgyYbLhi9Uk899VQaPHjwvxvTtm1ef+yxx+o85s4770yDBg3KwwV79uyZtt5663TBBRekRYsWLfN13n///fzh1VwAAAAaSpOFrDlz5uRwFGGpplifMWNGncdMnTo1DxOM42Ie1llnnZUuvfTSdP755y/zdUaPHp3TadUSPWUAAAAttvBFfcRwwpiPdc0116QddtghDR06NH33u9/NwwiXZeTIkbn7r2qZPn16o7YZAABoXZqs8EX37t1Tu3bt0syZM2ttj/VevXrVeUxUFIy5WHFclS222CL3fMXww44dOy51TFQgjAUAAGCl7Mn6yU9+ku6+++7q9dNOOy1X99t1111zpb8VFYEoeqMmTpxYq6cq1mPeVV1222239NJLL+X9qrz44os5fNUVsAAAAFb6kBWFJlZZZZX8OApUxH2uLrrootwzdeKJJ9brXFG+/dprr83BbfLkyemb3/xmmj9/fjriiCPy88OGDcvD/arE82+88UY64YQTcriKsBftiUIYAAAAzXK4YMxp2njjjfPjO+64I33xi19MRx99dO5l+vSnP12vc8WcqtmzZ6dRo0blIX8DBgxIEyZMqC6GMW3atFxxsEoUrbj33ntzmNt2223zfbIicJ1++un1fRsAAAArx32yovBEBJ3tttsuL9Ebdfjhh6eXX3459e/fP73zzjtpZeY+WQAAQENmg3r3ZO29997pqKOOygErhuztt99+efuf//zn1K9fv2INAwAAaBVzsmIOVhSmiGF+v/jFL9Laa6+dt8eNhQ855JCGaCMAAEDLHS7Y3BkuCAAANGQ2qHdPVhSmePjhh2v1bEXBikMPPTS9+eabxRoGAADQHNU7ZJ166qk58YXnnnsunXzyyXle1iuvvJKLYAAAALRm9S58EWFqyy23zI9jTtbnP//5fK+qp59+uroIBgAAQGtV756sjh07pgULFuTH999/f9pnn33y47XWWqu6hwsAAKC1qndP1u67756HBcbNhydNmpTGjx+ft0c590996lMN0UYAAICW25N15ZVXpvbt26dbb701XX311alPnz55+69//eu07777NkQbAQAAmg0l3AEAgFZpXgNlg3oPFwyLFi1Kd9xxR5o8eXJe32qrrdKBBx6Y2rVrV6xhAAAAzVG9Q9ZLL72Uqwi+9tprabPNNsvbRo8enfr27ZvuvvvutNFGGzVEOwEAAFrmnKxvf/vbOUhNnz49l22PZdq0aWmDDTbIzwEAALRm9e7J+u1vf5sef/zxXLK9ytprr50uvPDCXHEQAACgNat3T1anTp3S22+/vdT2d955J99DCwAAoDWrd8j6/Oc/n44++uj0hz/8IUVhwliiZ+uYY47JxS8AAABas3qHrB/+8Id5TtagQYNS586d8xLDBDfeeOM0ZsyYhmklAABAS52TtcYaa6Rf/vKXucpgVQn3LbbYIocsAACA1u5j3ScrRKiqGaz+9Kc/pYEDB6aFCxeWahsAAEDLHy64LDE3K25SDAAA0JoVC1kAAAAIWQAAAE0zJ2vevHnLfb6ue2cBAAC0Nu3rU1WwTZs2y52TtbznAQAAWoMVDlkPPvhgw7YEAACgNYWsPffcs2FbAgAA0AIofAEAAFCQkAUAAFCQkAUAAFCQkAUAAFCQkAUAANAU1QWrHHzwwXXeDyu2de7cOW288cbp0EMPTZtttlmpNgIAALTcnqxu3bqlBx54ID399NM5WMXyzDPP5G0ffvhhGj9+fOrfv3965JFHGqbFAAAALaknq1evXrmn6sorr0xt2/4roy1evDidcMIJafXVV08333xzOuaYY9Lpp5+eHn744YZoMwAAwEqrTaVSqdTngHXWWSf3Um266aa1tr/44otp1113TXPmzEnPPfdc2mOPPdJbb72VVjbz5s3LvXFz585NXbt2bermAAAALSwb1Hu4YAwJnDJlylLbY9uiRYvy45ibVde8LQAAgJau3sMFDz/88HTkkUemM844I+2444552xNPPJEuuOCCNGzYsLz+29/+Nm211VblWwsAANDSQtbll1+eevbsmS666KI0c+bMvC3WTzzxxDwPK+yzzz5p3333Ld9aAACAljYna8kxjKE5zW0yJwsAAGjIbFDvnqyahBQAAIBPWPgihgjGvKx11103tW/fPrVr167WAgAA0JrVuyfrq1/9apo2bVo666yzUu/evVURBAAA+CQhK24w/Pvf/z4NGDCgvocCAAC0ePUeLti3b9/0CWplAAAAtGj1DlljxoxJI0aMSK+++mrDtAgAAKA1DRccOnRoWrBgQdpoo41Sly5dUocOHWo9/8Ybb5RsHwAAQMsOWdGTBQAAQKGQNXz48PoeAgAA0Gq0X9E7IVfdeDgeL48bFAMAAK3ZCoWsNddcM73++uupR48eaY011qjz3lhRcTC2L1q0qCHaCQAA0HJC1gMPPJDWWmut/PjBBx9s6DYBAAA0W20qreymVzHcsVu3bmnu3LmGNgIAQCs2r4GyQb0LX4S33norTZo0Kc2aNSstXry41nPDhg0r1TYAAIBmp94h61e/+lU67LDD0jvvvJPTXs35WfFYyAIAAFqztvU94OSTT05f+9rXcsiKHq0333yzenEjYgAAoLWrd8h67bXX0re//e3UpUuXhmkRAABAawpZQ4YMSU8++WTDtAYAAKC1zcnaf//906mnnpr+8pe/pG222SZ16NCh1vMHHnhgyfYBAAC07BLubdsuu/OrOdyMWAl3AABgpSrhvmTJdgAAAD7BnCwAAAA+YU/WD3/4w3T00Uenzp0758fLE5UHAQAAWqsVmpO1wQYb5IqCa6+9dn68zJO1aZOmTp2aVmbmZAEAAE0+J+uVV16p8zEAAAC1mZMFAABQUL2rC4a///3v6c4770zTpk1LCxcurPXcZZddVqptAAAALT9kTZw4Md9weMMNN0xTpkxJW2+9dXr11VdTTO3afvvtG6aVAAAALXW44MiRI9Mpp5ySnnvuuVxt8Be/+EWaPn162nPPPdN//ud/NkwrAQAAWmrImjx5cho2bFh+3L59+/Tuu++m1VZbLX3ve99LP/jBDxqijQAAAC03ZK266qrV87B69+6dXn755ern5syZU7Z1AAAALX1O1i677JIefvjhtMUWW6T99tsvnXzyyXno4G233ZafAwAAaM3qHbKieuA777yTH5977rn58fjx49Mmm2yisiAAANDq1StkLVq0KJdv33bbbauHDo4bN66h2gYAANCy52S1a9cu7bPPPunNN99suBYBAAC0psIXcV+sqVOnNkxrAAAAWlvIOv/88/N9su666670+uuvp3nz5tVaAAAAWrM2lUqlsiI7xn2wopLg6quv/u+D27SpfhynifWYt7UyiyDYrVu3NHfu3NS1a9embg4AANDCssEKh6yYjxU9V3Ez4uXZc88908pMyAIAABoyG6xwdcGqLLayhygAAIBmMyer5vBAAAAAPuF9sjbddNOPDFpvvPFGfU4JAADQekPWueeem8csljZ27Nh08cUXpxkzZqT+/funK664Iu20004fedzNN9+cDjnkkPSFL3wh3XHHHcXbBQAA0KAh6ytf+Urq0aNHKmn8+PHppJNOSuPGjUs777xzGjNmTBoyZEh64YUXlvtar776ai4lv8ceexRtDwAAQKPMyWqo+ViXXXZZ+vrXv56OOOKItOWWW+aw1aVLl3T99dcv85goE3/YYYflnrUNN9ywQdoFAADQoCFrBSu918vChQvTU089lQYPHvzvBrVtm9cfe+yx5d6zK3q5jjzyyI98jffff98NkwEAgJVvuODixYuLv/icOXNyr1TPnj1rbY/1KVOm1HnMww8/nK677rr07LPPrtBrjB49Ovd4AQAArHQl3Jva22+/nQ4//PB07bXXpu7du6/QMSNHjsw3F6tapk+f3uDtBAAAWq96Fb4oLYJSu3bt0syZM2ttj/VevXottf/LL7+cC14ccMABS/WwtW/fPhfL2GijjWod06lTp7wAAAC0+J6sjh07ph122CFNnDixVmiK9UGDBi21/+abb56ee+65PFSwajnwwAPTXnvtlR/37du3kd8BAADAStSTFaJ8+/Dhw9PAgQPzvbGihPv8+fNztcEwbNiw1KdPnzy3qnPnzmnrrbeudfwaa6yRfy65HQAAoFWGrKFDh6bZs2enUaNG5ZsRDxgwIE2YMKG6GMa0adNyxUEAAIDmoE2lIWqzr8SihHu3bt1yEYyuXbs2dXMAAIAWlg10EQEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAALS0kDV27NjUr1+/1Llz57TzzjunSZMmLXPfa6+9Nu2xxx5pzTXXzMvgwYOXuz8AAECrClnjx49PJ510Ujr77LPT008/nfr375+GDBmSZs2aVef+Dz30UDrkkEPSgw8+mB577LHUt2/ftM8++6TXXnut0dsOAACwpDaVSqWSmlD0XO24447pyiuvzOuLFy/Owen4449PI0aM+MjjFy1alHu04vhhw4Z95P7z5s1L3bp1S3Pnzk1du3Yt8h4AAIDmZ14DZYMm7clauHBheuqpp/KQv+oGtW2b16OXakUsWLAgffDBB2mttdaq8/n3338/f3g1FwAAgIbSpCFrzpw5uSeqZ8+etbbH+owZM1boHKeffnpad911awW1mkaPHp3TadUSvWQAAAAtdk7WJ3HhhRemm2++Od1+++25aEZdRo4cmbv/qpbp06c3ejsBAIDWo31Tvnj37t1Tu3bt0syZM2ttj/VevXot99hLLrkkh6z7778/bbvttsvcr1OnTnkBAABo8T1ZHTt2TDvssEOaOHFi9bYofBHrgwYNWuZxF110UTrvvPPShAkT0sCBAxuptQAAACt5T1aI8u3Dhw/PYWmnnXZKY8aMSfPnz09HHHFEfj4qBvbp0yfPrQo/+MEP0qhRo9KNN96Y761VNXdrtdVWywsAAECrDllDhw5Ns2fPzsEpAtOAAQNyD1VVMYxp06blioNVrr766lyV8Etf+lKt88R9ts4555xGbz8AAMBKdZ+sxuY+WQAAQIu9TxYAAEBLI2QBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAAUJGQBAAC0tJA1duzY1K9fv9S5c+e08847p0mTJi13/1tuuSVtvvnmef9tttkm3XPPPY3WVgAAgJU6ZI0fPz6ddNJJ6eyzz05PP/106t+/fxoyZEiaNWtWnfs/+uij6ZBDDklHHnlkeuaZZ9JBBx2Ul+eff77R2w4AALCkNpVKpZKaUPRc7bjjjunKK6/M64sXL059+/ZNxx9/fBoxYsRS+w8dOjTNnz8/3XXXXdXbdtlllzRgwIA0bty4j3y9efPmpW7duqW5c+emrl27Fn43AABAc9FQ2aB9akILFy5MTz31VBo5cmT1trZt26bBgwenxx57rM5jYnv0fNUUPV933HFHnfu///77eakSH2DVBwoAALRe8/7/TFC636lJQ9acOXPSokWLUs+ePWttj/UpU6bUecyMGTPq3D+212X06NHp3HPPXWp79JYBAAD885//zD1aLSJkNYboJavZ8/XWW2+l9ddfP02bNq3oBwl1/WUkwvz06dMNTaVBudZoLK41GotrjcYSo9zWW2+9tNZaaxU9b5OGrO7du6d27dqlmTNn1toe67169arzmNhen/07deqUlyVFwPIfLY0hrjPXGo3BtUZjca3RWFxrNJaYslT0fKkJdezYMe2www5p4sSJ1dui8EWsDxo0qM5jYnvN/cN99923zP0BAAAaU5MPF4yhfMOHD08DBw5MO+20UxozZkyuHnjEEUfk54cNG5b69OmT51aFE044Ie25557p0ksvTfvvv3+6+eab05NPPpmuueaaJn4nAAAAK0HIipLss2fPTqNGjcrFK6IU+4QJE6qLW8TcqZrdd7vuumu68cYb05lnnpnOOOOMtMkmm+TKgltvvfUKvV4MHYx7ctU1hBBKcq3RWFxrNBbXGo3FtUZzv9aa/D5ZAAAALUmTzskCAABoaYQsAACAgoQsAACAgoQsAACAglpkyBo7dmzq169f6ty5c9p5553TpEmTlrv/LbfckjbffPO8/zbbbJPuueeeRmsrredau/baa9Mee+yR1lxzzbwMHjz4I69N+Lj/rlWJ21y0adMmHXTQQQ3eRlrntfbWW2+l4447LvXu3TtX59p00039/ygNcq3FbX4222yztMoqq6S+ffumE088Mb333nuN1l6ap9/97nfpgAMOSOuuu27+/8OoSv5RHnroobT99tvnf9M23njj9OMf/7jer9viQtb48ePzvbeiFOPTTz+d+vfvn4YMGZJmzZpV5/6PPvpoOuSQQ9KRRx6ZnnnmmfxFJJbnn3++0dtOy77W4j/YuNYefPDB9Nhjj+X/g9hnn33Sa6+91uhtp3mp77VW5dVXX02nnHJKDvfQENfawoUL0957752vtVtvvTW98MIL+Q9KcX9LKHmtxe17RowYkfefPHlyuu666/I54nY+sDxx/924viLUr4hXXnkl34t3r732Ss8++2z6zne+k4466qh07733pnqptDA77bRT5bjjjqteX7RoUWXdddetjB49us79v/zlL1f233//Wtt23nnnyje+8Y0Gbyut61pb0ocfflhZffXVKz/5yU8asJW01mstrq9dd9218qMf/agyfPjwyhe+8IVGai2t6Vq7+uqrKxtuuGFl4cKFjdhKWuO1Fvt+5jOfqbXtpJNOquy2224N3lZajpRS5fbbb1/uPqeddlplq622qrVt6NChlSFDhtTrtVpUT1b8Re2pp57Kw7CqxI2MYz16DuoS22vuH+IvKcvaHz7utbakBQsWpA8++CCttdZaDdhSWuu19r3vfS/16NEj99JDQ11rd955Zxo0aFAeLtizZ8+09dZbpwsuuCAtWrSoEVtOa7jWdt1113xM1ZDCqVOn5mGp++23X6O1m9bhsULZoH1qQebMmZP/YY9/6GuK9SlTptR5zIwZM+rcP7ZDyWttSaeffnoeH7zkf8jwSa+1hx9+OA+liWEO0JDXWnzRfeCBB9Jhhx2Wv/C+9NJL6dhjj81/QIphXVDqWjv00EPzcbvvvnuMwkoffvhhOuaYYwwXpLhlZYN58+ald999N88JXBEtqicLmosLL7wwFyS4/fbb84RfKOXtt99Ohx9+eJ4X071796ZuDi3c4sWLc4/pNddck3bYYYc0dOjQ9N3vfjeNGzeuqZtGCxPzmqOX9KqrrspzuG677bZ09913p/POO6+pmwYtvycrvlC0a9cuzZw5s9b2WO/Vq1edx8T2+uwPH/daq3LJJZfkkHX//fenbbfdtoFbSmu71l5++eVchCAqKdX8Ihzat2+fCxNstNFGjdByWsO/a1FRsEOHDvm4KltssUX+S3AMCevYsWODt5vWca2dddZZ+Q9IUYAgRDXoKGhw9NFH52Afww2hhGVlg65du65wL1ZoUVdk/GMef0mbOHFirS8XsR5jxusS22vuH+67775l7g8f91oLF110Uf6r24QJE9LAgQMbqbW0pmstbkfx3HPP5aGCVcuBBx5YXSUpqlpCqX/XdttttzxEsCrIhxdffDGHLwGLktdazGNeMkhVhft/1TOAMoplg0oLc/PNN1c6depU+fGPf1z5y1/+Ujn66KMra6yxRmXGjBn5+cMPP7wyYsSI6v0feeSRSvv27SuXXHJJZfLkyZWzzz670qFDh8pzzz3XhO+ClnitXXjhhZWOHTtWbr311srrr79evbz99ttN+C5oidfaklQXpKGutWnTpuUqqd/61rcqL7zwQuWuu+6q9OjRo3L++ec34bugJV5r8f0srrWbbrqpMnXq1MpvfvObykYbbZSrRMPyxPesZ555Ji8RfS677LL8+G9/+1t+Pq6zuN6qxPXVpUuXyqmnnpqzwdixYyvt2rWrTJgwoVIfLS5khSuuuKKy3nrr5S+0USL08ccfr35uzz33zF84avr5z39e2XTTTfP+UbLx7rvvboJW09KvtfXXXz//x73kEv/HAaX/XatJyKIhr7VHH3003/okvjBHOffvf//7+RYCUPJa++CDDyrnnHNODladO3eu9O3bt3LsscdW3nzzzSZqPc3Fgw8+WOf3r6rrK37G9bbkMQMGDMjXZvy7dsMNN9T7ddvE/xTqXQMAAGj1WtScLAAAgKYmZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAEAABQkZAFAPbRp0ybdcccdTd0MAFZiQhYAzcZXv/rVHHKWXPbdd9+mbhoAVGv/74cAsPKLQHXDDTfU2tapU6cmaw8ALElPFgDNSgSqXr161VrWXHPN/Fz0al199dXpc5/7XFpllVXShhtumG699dZaxz/33HPpM5/5TH5+7bXXTkcffXR65513au1z/fXXp6222iq/Vu/evdO3vvWtWs/PmTMnHXzwwalLly5pk002SXfeeWcjvHMAmgshC4AW5ayzzkpf/OIX0x//+Md02GGHpa985Stp8uTJ+bn58+enIUOG5FD2xBNPpFtuuSXdf//9tUJUhLTjjjsuh68IZBGgNt5441qvce6556Yvf/nL6U9/+lPab7/98uu88cYbjf5eAVg5talUKpWmbgQArOicrJ/+9Kepc+fOtbafccYZeYmerGOOOSYHpSq77LJL2n777dNVV12Vrr322nT66aen6dOnp1VXXTU/f88996QDDjgg/eMf/0g9e/ZMffr0SUcccUQ6//zz62xDvMaZZ56ZzjvvvOrgttpqq6Vf//rX5oYBkJmTBUCzstdee9UKUWGttdaqfjxo0KBaz8X6s88+mx9Hj1b//v2rA1bYbbfd0uLFi9MLL7yQA1SErc9+9rPLbcO2225b/TjO1bVr1zRr1qxP/N4AaBmELACalQg1Sw7fKyXmaa2IDh061FqPcBZBDQCCOVkAtCiPP/74UutbbLFFfhw/Y65WDPGr8sgjj6S2bdumzTbbLK2++uqpX79+aeLEiY3ebgBaDj1ZADQr77//fpoxY0atbe3bt0/du3fPj6OYxcCBA9Puu++efvazn6VJkyal6667Lj8XBSrOPvvsNHz48HTOOeek2bNnp+OPPz4dfvjheT5WiO0xr6tHjx65SuHbb7+dg1jsBwArQsgCoFmZMGFCLqteU/RCTZkypbry380335yOPfbYvN9NN92Uttxyy/xclFy/99570wknnJB23HHHvB6VCC+77LLqc0UAe++999Lll1+eTjnllBzevvSlLzXyuwSgOVNdEIAWI+ZG3X777emggw5q6qYA0IqZkwUAAFCQkAUAAFCQOVkAtBhGwAOwMtCTBQAAUJCQBQAAUJCQBQAAUJCQBQAAUJCQBQAAUJCQBQAAUJCQBQAAUJCQBQAAkMr5/wDg8I56W5xCcQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load all mlflow final epoch loss\n",
    "# plot against architecture and dimension\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the experiment ID or name\n",
    "experiment_id = \"dot_product\"\n",
    "# mlf_logger = MLFlowLogger(experiment_name=\"dot_product\", tracking_uri=\"experiments\")\n",
    "\n",
    "# Load all runs from the experiment\n",
    "client = mlflow.tracking.MlflowClient(tracking_uri=\"experiments\")\n",
    "runs = client.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "# Extract training losses\n",
    "losses = {}\n",
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "    metrics = client.get_metric_history(run_id, \"training_loss\")\n",
    "    losses[run_id] = [metric.value for metric in metrics]\n",
    "\n",
    "# Plot the training losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "for run_id, loss_values in losses.items():\n",
    "    plt.plot(loss_values, label=f\"Run {run_id}\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Losses for All Runs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
